import asyncio
import aiohttp
import os
from header_generator import random_user_agent
from html_fetcher import HTMLFetcher


async def main():
    base_url = "https://motorland.by/minsk-auto-parts/?pg={page}"

    # üìÅ –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è HTML
    out_dir = os.path.join(os.path.dirname(__file__), "responses2")
    os.makedirs(out_dir, exist_ok=True)

    # –°–æ–∑–¥–∞—ë–º —Å—Ç–∞—Ä—Ç–æ–≤—É—é —Å–µ—Å—Å–∏—é
    headers = {"User-Agent": random_user_agent()}
    async with aiohttp.ClientSession(headers=headers) as session:
        fetcher = HTMLFetcher(session)

        # –ü—Ä–æ–±–µ–≥–∞–µ–º—Å—è –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º 1‚Äì100
        for i in range(5000, 7000):
            ua = random_user_agent()
            session.headers.update({"User-Agent": ua})
            url = base_url.format(page=i)

            try:
                html = await fetcher.fetch(url)
                if html:
                    filename = os.path.join(out_dir, f"page_{i:03d}.html")
                    with open(filename, "w", encoding="utf-8") as f:
                        f.write(html)

                    print(f"[{i}] ‚úÖ OK ‚Äî saved {os.path.basename(filename)}")
                    print(f"     URL: {url}")
                    print(f"     UA:  {ua}")
                else:
                    print(f"[{i}] ‚ùå FAIL (empty response) ‚Äî {url}")
            except Exception as e:
                print(f"[{i}] ‚ö†Ô∏è Error fetching {url}: {e}")

            await asyncio.sleep(0.3)  # –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω. –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'responses/'")


if __name__ == "__main__":
    asyncio.run(main())
